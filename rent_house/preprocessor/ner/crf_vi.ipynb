{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi.pyvi import ViTokenizer,ViPosTagger\n",
    "\n",
    "def readFile_txt(filename):\n",
    "    data=[]\n",
    "    f = open(filename)\n",
    "#     next(f)\n",
    "    for row in f:\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def make_data_train(data):\n",
    "    data_train=[]\n",
    "    for row in data:\n",
    "        post_tup=ViPosTagger.postagging(ViTokenizer.tokenize(row))\n",
    "        post_list=tupToList(post_tup)\n",
    "        data_train.append(post_list)\n",
    "    return data_train\n",
    "\n",
    "def writeListFile(filename,data):\n",
    "    str_out=''\n",
    "    for item in data:\n",
    "        for tup in item:\n",
    "            str_out+=tup[0]+\" \"+tup[1]+\" \"+tup[2]+\"\\n\"\n",
    "        str_out+=\"\\n\"\n",
    "#     print(str_out)\n",
    "    F = open(filename,\"w\")\n",
    "    F.write(str(str_out))\n",
    "def tupToList(tup):\n",
    "    list1=[]\n",
    "    for item in tup[0]:\n",
    "        index=tup[0].index(item)\n",
    "        tup_=(item,tup[1][index],'0')\n",
    "        list1.append(tup_)\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=readFile_txt(\"train1\")\n",
    "data_train=make_data_train(data)\n",
    "\n",
    "writeListFile(\"train1.pre\",data_train)\n",
    "\n",
    "data=readFile_txt(\"test1\")\n",
    "data_test=make_data_train(data)\n",
    "\n",
    "writeListFile(\"test1.pre\",data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "# create data train\n",
    "file_train=\"train2.pre\"\n",
    "file_test=\"test2.pre\"\n",
    "data_train=readFile_txt(file_train)\n",
    "data_test=readFile_txt(file_test)\n",
    "# print(data_test)\n",
    "def getMatrix(data):\n",
    "    matrix=[]\n",
    "    vector=[]\n",
    "    line=0\n",
    "    for dt in data:\n",
    "        if len(dt)>1:\n",
    "            dt = dt[:-1]\n",
    "            l1=dt.split(\" \")\n",
    "            t1=(l1[0],l1[1],l1[2])\n",
    "            vector.append(t1)\n",
    "        else:\n",
    "            matrix.append(vector)\n",
    "            vector=[]\n",
    "    print (len(matrix))\n",
    "    return matrix\n",
    "matrix_train=getMatrix(data_train)\n",
    "matrix_test=getMatrix(data_test)\n",
    "# print(matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+1:postag': 'N',\n",
       " '+1:postag[:2]': 'N',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:word.lower()': 'đất',\n",
       " 'BOS': True,\n",
       " 'bias': 1.0,\n",
       " 'postag': 'N',\n",
       " 'postag[:2]': 'N',\n",
       " 'word.isdigit()': False,\n",
       " 'word.istitle()': True,\n",
       " 'word.isupper()': False,\n",
       " 'word.lower()': 'giá',\n",
       " 'word[-2:]': 'iá',\n",
       " 'word[-3:]': 'Giá'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(matrix_train[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 ms, sys: 0 ns, total: 48 ms\n",
      "Wall time: 57.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in matrix_train]\n",
    "y_train = [sent2labels(s) for s in matrix_train]\n",
    "\n",
    "X_test = [sent2features(s) for s in matrix_test]\n",
    "y_test = [sent2labels(s) for s in matrix_test]\n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 972 ms, sys: 52 ms, total: 1.02 s\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "import pickle\n",
    "f = open('../model/ner.pkl', 'wb')\n",
    "pickle.dump(crf, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['district',\n",
       " 'province',\n",
       " 'street',\n",
       " 'maxPrice',\n",
       " 'ward',\n",
       " 'unit',\n",
       " 'minPrice',\n",
       " 'minAcreage',\n",
       " 'project',\n",
       " 'bedRoom']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('0')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7716975206871105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "# print(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ward      0.500     1.000     0.667         1\n",
      "   maxPrice      0.667     1.000     0.800         4\n",
      "    bedRoom      1.000     0.333     0.500         3\n",
      " minAcreage      1.000     1.000     1.000         3\n",
      "   minPrice      1.000     0.500     0.667         4\n",
      "   district      0.833     0.833     0.833        18\n",
      "       unit      1.000     0.857     0.923         7\n",
      "    project      0.750     0.500     0.600         6\n",
      "   province      0.889     0.533     0.667        15\n",
      "     street      0.769     1.000     0.870        10\n",
      "\n",
      "avg / total      0.855     0.746     0.772        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[('thuê', 'V', '0'), ('văn_phòng', 'N', '0'), ('quận', 'N', '0'), ('Cầu_Giấy', 'Np', '0'), (',', 'F', '0'), ('Hà_Nội', 'Np', '0'), (',', 'F', '0'), ('giá', 'N', '0'), ('bao_nhiêu', 'A', '0')]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['0', '0', '0', 'district', '0', 'province', '0', '0', '0']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list_sentence=['thuê văn_phòng quận Cầu_Giấy , Hà_Nội , giá bao_nhiêu']\n",
    "filename=\"sentence_test\"\n",
    "test_sentence=make_data_train(test_list_sentence)\n",
    "# print(test_sentence)\n",
    "def writeListFile(data):\n",
    "    str_out=[]\n",
    "    for item in data:\n",
    "        for tup in item:\n",
    "            str_out.append(tup[0]+\" \"+tup[1]+\" \"+tup[2]+\"\\n\")\n",
    "\n",
    "    return str_out\n",
    "# print(writeListFile(test_sentence))\n",
    "data_test=readFile_txt(filename)\n",
    "# print(data_test)\n",
    "matrix_test_sentence=getMatrix(data_test)\n",
    "print(matrix_test_sentence)\n",
    "X_matrix_test_sentence = [sent2features(s) for s in matrix_test_sentence]\n",
    "y_pred = crf.predict(X_matrix_test_sentence)\n",
    "y_pred\n",
    "# X_matrix_test_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
